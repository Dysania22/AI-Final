::decision_cite:: 22-277
::decision_name::  Moody v. NetChoice, LLC
::decision_year:: 2024
::opinion_author:: Barrett
::opinion_type:: Concurrence
::opinion:: 

															

															SUPREME COURT OF THE UNITED STATES

															_________________

															Nos. 22–277 and 22–555

															_________________

															ASHLEY MOODY, ATTORNEY GENERAL OF
FLORIDA, et al., PETITIONERS

															22–277v.

															NETCHOICE, LLC, dba NETCHOICE, et
al.

															on writ of certiorari to the united states
court of appeals for the eleventh circuit

															

															NETCHOICE, LLC, dba NETCHOICE, et al.,
PETITIONERS

															22–555v.

															KEN PAXTON, ATTORNEY GENERAL OF
TEXAS

															on writ of certiorari to the united states
court of appeals for the fifth circuit

															[July 1, 2024]

															Justice Barrett, concurring.

															I join the Court’s opinion, which correctly
articulates and applies our First Amendment precedent. In this
respect, the Eleventh Circuit’s understanding of the First
Amendment’s protection of editorial discretion was generally
correct; the Fifth Circuit’s was not.

															But for the reasons the Court gives, these cases
illustrate the dangers of bringing a facial challenge. If
NetChoice’s members are concerned about preserving their editorial
discretion with respect to the services on which they have focused
throughout this litigation—e.g., Facebook’s Newsfeed
and YouTube’s homepage—they would be better served by bringing a
First Amendment challenge as applied to those functions. Analyzing
how the First Amendment bears on those functions is complicated
enough without simultaneously analyzing how it bears on a
platform’s other functions—e.g., Facebook Messenger and
Google Search—much less to distinct platforms like Uber and Etsy.
In fact, dealing with a broad swath of varied platforms and
functions in a facial challenge strikes me as a daunting, if not
impossible, task. A function qualifies for First Amendment
protection only if it is inherently expressive. Hurley v.
Irish-American Gay, Lesbian and Bisexual Group of Boston,
Inc., 515 U.S.
557, 568 (1995). Even for a prototypical social-media feed,
making this determination involves more than meets the eye.

															Consider, for instance, how platforms use
algorithms to prioritize and remove content on their feeds. Assume
that human beings decide to remove posts promoting a particular
political candidate or advocating some position on a public-health
issue. If they create an algorithm to help them identify and delete
that content, the First Amendment protects their exercise of
editorial judgment—even if the algorithm does most of the deleting
without a person in the loop. In that event, the algorithm would
simply implement human beings’ inherently expressive choice “to
exclude a message [they] did not like from” their speech
compilation. Id., at 574.

															But what if a platform’s algorithm just presents
automatically to each user whatever the algorithm thinks the user
will like—e.g., content similar to posts with which
the user previously engaged? See ante, at 22, n. 5. The
First Amendment implications of the Florida and Texas laws might be
different for that kind of algorithm. And what about AI, which is
rapidly evolving? What if a platform’s owners hand the reins to an
AI tool and ask it simply to remove “hateful” content? If the AI
relies on large language models to determine what is “hateful” and
should be removed, has a human being with First Amendment rights
made an inherently expressive “choice . . . not to
propound a particular point of view”? Hurley, 515
U. S., at 575. In other words, technology may attenuate the
connection between content-moderation actions
(e.g., removing posts) and human beings’
constitutionally protected right to “decide for
[themselves] the ideas and beliefs deserving of expression,
consideration, and adherence.” Turner Broadcasting System,
Inc. v. FCC, 512 U.S.
622, 641 (1994) (emphasis added). So the way platforms use this
sort of technology might have constitutional significance.

															There can be other complexities too. For
example, the corporate structure and ownership of some platforms
may be relevant to the constitutional analysis. A speaker’s right
to “decide ‘what not to say’ ” is “enjoyed by business
corporations generally.” Hurley, 515 U. S., at 573–574
(quoting Pacific Gas & Elec. Co. v. Public Util.
Comm’n of Cal., 475 U.S.
1, 16 (1986)). Corporations, which are composed of human beings
with First Amendment rights, possess First Amendment rights
themselves. See Citizens United v. Federal Election
Comm’n, 558 U.S.
310, 365 (2010); cf. Burwell v. Hobby Lobby Stores,
Inc., 573 U.S.
682, 706–707 (2014). But foreign persons and corporations
located abroad do not. Agency for Int’l Development v.
Alliance for Open Society Int’l, Inc., 591 U.S. 430, 433–436
(2020). So a social-media platform’s foreign ownership and control
over its content-moderation decisions might affect whether laws
overriding those decisions trigger First Amendment scrutiny. What
if the platform’s corporate leadership abroad makes the policy
decisions about the viewpoints and content the platform will
disseminate? Would it matter that the corporation employs Americans
to develop and implement content- moderation algorithms if they do
so at the direction of foreign executives? Courts may need to
confront such questions when applying the First Amendment to
certain platforms.

															These are just a few examples of questions that
might arise in litigation that more thoroughly exposes the relevant
facts about particular social-media platforms and functions. The
answers in any given case might cast doubt on—or might vindicate—a
social-media company’s invocation of its First Amendment rights.
Regardless, the analysis is bound to be fact intensive, and it will
surely vary from function to function and platform to platform. And
in a facial challenge, answering all of those questions isn’t even
the end of the story: The court must then find a way to measure the
unconstitutional relative to the constitutional applications to
determine whether the law “prohibits a substantial amount of
protected speech relative to its plainly legitimate sweep.”
United States v. Hansen, 599 U.S. 762, 770 (2023)
(internal quotation marks omitted).

															A facial challenge to either of these laws
likely forces a court to bite off more than it can chew. An
as-applied challenge, by contrast, would enable courts to home in
on whether and how specific functions—like feeds versus direct
messaging—are inherently expressive and answer platform- and
function-specific questions that might bear on the First Amendment
analysis. While the governing constitutional principles are
straightforward, applying them in one fell swoop to the entire
social-media universe is not.

													
