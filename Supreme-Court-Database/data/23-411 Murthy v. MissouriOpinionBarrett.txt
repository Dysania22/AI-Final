::decision_cite:: 23-411
::decision_name::  Murthy v. Missouri
::decision_year:: 2024
::opinion_author:: Barrett
::opinion_type:: Opinion
::opinion:: 

															

															NOTICE: This opinion is subject to
formal revision before publication in the United States Reports.
Readers are requested to notify the Reporter of Decisions, Supreme
Court of the United States, Washington, D. C. 20543,
pio@supremecourt.gov, of any typographical or other formal
errors.

															SUPREME COURT OF THE UNITED STATES

															_________________

															No. 23–411

															_________________

															VIVEK H. MURTHY, SURGEON GENERAL, et al.,
PETITIONERS v. MISSOURI, et al.

															on writ of certiorari to the united states
court of appeals for the fifth circuit

															[June 26, 2024]

															Justice Barrett delivered the opinion of the
Court.

															During the 2020 election season and the COVID–19
pandemic, social-media platforms frequently removed, demoted, or
fact checked posts containing allegedly false or misleading
information. At the same time, federal officials, concerned about
the spread of “misinformation” on social media, communicated
extensively with the platforms about their content-moderation
efforts.

															The plaintiffs, two States and five social-media
users, sued dozens of Executive Branch officials and agencies,
alleging that they pressured the platforms to suppress protected
speech in violation of the First Amendment. The Fifth Circuit
agreed, concluding that the officials’ communications rendered them
responsible for the private platforms’ moderation decisions. It
then affirmed a sweeping preliminary injunction.

															The Fifth Circuit was wrong to do so. To
establish standing, the plaintiffs must demonstrate a substantial
risk that, in the near future, they will suffer an injury that is
traceable to a Government defendant and redressable by the
injunction they seek. Because no plaintiff has carried that burden,
none has standing to seek a preliminary injunction.

															I

															A

															With their billions of active users, the
world’s major social-media companies host a “staggering” amount of
content on their platforms. Twitter, Inc. v. Taamneh,
598 U.S. 471, 480 (2023). Yet for many of these companies,
including Facebook, Twitter, and YouTube, not everything
goes.[1] Under their
longstanding content-moderation policies, the platforms have taken
a range of actions to suppress certain categories of speech. They
place warning labels on some posts, while deleting others. They
also “demote” content so that it is less visible to other users.
And they may suspend or ban users who frequently post content that
violates platform policies.

															For years, the platforms have targeted speech
they judge to be false or misleading. For instance, in 2016,
Facebook began fact checking and demoting posts containing
misleading claims about elections. Since 2018, Facebook has removed
health-related misinformation, including false claims about a
measles outbreak in Samoa and the polio vaccine in Pakistan.
Likewise, in 2019, YouTube announced that it would “demonetize”
channels that promote anti-vaccine messages.

															In 2020, with the outbreak of COVID–19, the
platforms announced that they would enforce their policies against
users who post false or misleading content about the pandemic. As
early as January 2020, Facebook deleted posts it deemed false
regarding “cures,” “treatments,” and the effect of “physical
distancing.” 60 Record on Appeal 19,035 (Record). And it demoted
posts containing what it described as “conspiracy theories about
the origin of the virus.” Id., at 19,036. Twitter and
YouTube began applying their policies in March and May 2020,
respectively. Throughout the pandemic, the platforms removed or
reduced posts questioning the efficacy and safety of mask wearing
and the COVID–19 vaccine, along with posts on related topics.

															The platforms also applied their misinformation
policies during the 2020 Presidential election season. Facebook, in
late 2019, unveiled measures to counter foreign interference
campaigns and voter suppression efforts. One month before the
election, multiple platforms suppressed a report about Hunter
Biden’s laptop, believing that the story originated from a Russian
hack-and-leak operation. After the election, the platforms took
action against users or posts that questioned the integrity of the
election results.

															Over the past few years, various federal
officials regularly spoke with the platforms about COVID–19 and
election-related misinformation. Officials at the White House, the
Office of the Surgeon General, and the Centers for Disease Control
and Prevention (CDC) focused on COVID–19 content, while the Federal
Bureau of Investigation (FBI) and the Cybersecurity and
Infrastructure Security Agency (CISA) concentrated on
elections.

															White House. In early 2021, and
continuing primarily through that year, the Director of Digital
Strategy and members of the COVID–19 response team interacted with
the platforms about their efforts to suppress vaccine
misinformation. They expressed concern that Facebook in particular
was “one of the top drivers of vaccine hesitancy,” due to the
spread of allegedly false or misleading claims on the platform.
App. 659–660. Thus, the officials peppered Facebook (and to a
lesser extent, Twitter and YouTube) with detailed questions about
their policies, pushed them to suppress certain content, and
sometimes recommended policy changes. Some of these communications
were more aggressive than others. For example, the director of
Digital Strategy, frustrated that Facebook had not removed a
particular post, complained: “[L]ast time we did this dance, it
ended in an insurrection.” Id., at 698. Another official,
unhappy with Facebook’s supposed lack of transparency about its
vaccine misinformation problems, wrote: “Internally we have been
considering our options on what to do about it.” Id., at
657. Publicly, White House communications officials called on the
platforms to do more to address COVID–19 misinformation—and,
perhaps as motivation, raised the possibility of reforms aimed at
the platforms, including changes to the antitrust laws and 47
U. S. C. §230.

															Surgeon General. In July 2021, Surgeon
General Vivek Murthy issued a health advisory on misinformation.
The advisory encouraged platforms to “[r]edesign recommendation
algorithms to avoid amplifying misinformation,” “[i]mpose clear
consequences for accounts that repeatedly violate platform
policies,” and “[p]rovide information from trusted and credible
sources to prevent misconceptions from taking hold.” 3 Record 662.
At a press conference to announce the advisory, Surgeon General
Murthy argued that the platforms should “operate with greater
transparency and accountability.” 2 id., at 626. The
following year, the Surgeon General issued a “Request for
Information,” seeking, among other things, reports on each
platform’s “COVID–19 misinformation policies.” Impact of Health
Misinformation in the Digital Information Environment in the United
States Throughout the COVID–19 Pandemic Request for Information
(RFI), 87 Fed. Reg. 12714 (Mar. 7, 2022).

															CDC. Like the White House, the CDC
frequently communicated with the platforms about COVID–19
misinformation. In early 2020, Facebook reached out to the agency,
seeking authoritative information about the virus that it could
post on the platform. The following year, the CDC’s communications
expanded to other platforms, including Twitter and YouTube. The CDC
hosted meetings and sent reports to the platforms, alerting them to
misinformation trends and flagging example posts. The platforms
often asked the agency for fact checks on specific claims.

															FBI and CISA. These agencies communicated
with the platforms about election-related misinformation. They
hosted meetings with several platforms in advance of the 2020
Presidential election and the 2022 midterms. The FBI alerted the
platforms to posts containing false information about voting, as
well as pernicious foreign influence campaigns that might spread on
their sites. Shortly before the 2020 election, the FBI warned the
platforms about the potential for a Russian hack-and-leak
operation. Some companies then updated their moderation policies to
prohibit users from posting hacked materials. Until mid-2022, CISA,
through its “switchboarding” operations, forwarded third-party
reports of election-related misinformation to the platforms. These
communications typically stated that the agency “w[ould] not take
any action, favorable or unfavorable, toward social media companies
based on decisions about how or whether to use this information.”
72 Record 23,223.

															B

															Respondents are two States and five individual
social-media users. They were the plaintiffs below, and for the
sake of narrative clarity, we will refer to them as “plaintiffs” in
this opinion. (Likewise, we will refer to the Government
individuals and agencies as “defendants” rather than petitioners.)
The individual plaintiffs—three doctors, the owner of a news
website, and a healthcare activist—allege that various platforms
removed or demoted their COVID–19 or election-related content
between 2020 and 2023. The States, Missouri and Louisiana, claim
that the platforms have suppressed the speech of state entities and
officials, as well as their citizens’ speech.

															Though the platforms restricted the plaintiffs’
content, the plaintiffs maintain that the Federal Government was
behind it. Acting on that belief, the plaintiffs sued dozens of
Executive Branch officials and agencies, alleging that they
pressured the platforms to censor the plaintiffs’ speech in
violation of the First Amendment. The States filed their complaint
on May 5, 2022. The next month, they moved for a preliminary
injunction, seeking to stop the defendants from “taking any steps
to demand, urge, encourage, pressure, or otherwise induce” any
platform “to censor, suppress, remove, de-platform, suspend,
shadow-ban, de-boost, restrict access to content, or take any other
adverse action against any speaker, content, or viewpoint expressed
on social media.” 1 id., at 253. The individual plaintiffs
joined the suit on August 2, 2022.

															After granting extensive discovery, the District
Court issued a preliminary injunction. Missouri v.
Biden, 680 F. Supp. 3d 630, 729 (WD La. 2023). The
court held that officials at the White House, the Surgeon General’s
Office, the CDC, the FBI, and CISA likely “coerced” or
“significantly encouraged” the platforms “to such extent that
the[ir content-moderation] decision[s] should be deemed to be the
decisions of the Government.” Id., at 694 (internal
quotation marks omitted). It enjoined those agencies, along with
scores of named and unnamed officials and employees, from taking
actions “for the purpose of urging, encouraging, pressuring, or
inducing in any manner the removal, deletion, suppression, or
reduction of content containing protected free speech posted on
social-medial platforms.” Missouri v. Biden, 2023 WL
5841935, *1–*2 (WD La., July 4, 2023).[2]

															Following a grant of panel rehearing, the Fifth
Circuit affirmed in part and reversed in part. Missouri v.
Biden, 83 F. 4th 350 (2023). It first held that the
individual plaintiffs had Article III standing to seek injunctive
relief, reasoning that the social-media companies had suppressed
the plaintiffs’ speech in the past and were likely to do so again
in the future, id., at 367–369, and that both of these
injuries were “traceable to government-coerced enforcement” of the
platform’s policies and “redressable by an injunction against the
government officials,” id., at 373. The court also concluded
that the States had standing, both because the platforms had
restricted the posts of individual state officials and because the
States have the “right to listen” to their citizens on social
media. Id., at 371–372.

															On the merits, the Fifth Circuit explained that
“a private party’s conduct may be state action if the government
coerced or significantly encouraged it.” Id., at 380 (citing
Blum v. Yaretsky, 457 U.S.
991, 1004 (1982); emphasis deleted). To identify coercion, it
asked whether “the government compelled the [private party’s]
decision by . . . intimating that some form of punishment
will follow a failure to comply.” 83 F. 4th, at 380. The court
explained that the Government significantly encourages a private
party’s choice when it exercises “active, meaningful control,
whether by entanglement in the party’s decision-making process or
direct involvement in carrying out the decision itself.”
Id., at 377.[3]

															Applying those tests, the Fifth Circuit
determined that White House officials, in conjunction with the
Surgeon General’s Office, likely both coerced and
significantly encouraged the platforms to moderate content.
Id., at 388. The court concluded that the same was true for
the FBI. Ibid. It held that the CDC and CISA significantly
encouraged (but did not coerce) the platforms’ moderation
decisions. Id., at 389, 391.

															The Fifth Circuit agreed with the District Court
that the equities favored the plaintiffs. Id., at 392–394.
It then modified the District Court’s injunction to state that the
defendants, and their employees and agents, shall not
“ ‘coerce or significantly encourage social-media companies to
remove, delete, suppress, or reduce, including through altering
their algorithms, posted social-media content containing protected
free speech.’ ” Id., at 397. The court did not limit
the injunction to the platforms that the plaintiffs use or the
topics that the plaintiffs wish to discuss, explaining that the
harms stemming from the defendants’ conduct “impac[t] every
social-media user.” Id., at 398.

															The federal agencies and officials applied to
this Court for emergency relief. We stayed the injunction, treated
the application as a petition for a writ of certiorari, and granted
the petition. 601 U. S. ___ (2023).

															II

															We begin—and end—with standing. At this stage,
neither the individual nor the state plaintiffs have established
standing to seek an injunction against any defendant. We therefore
lack jurisdiction to reach the merits of the dispute.

															A

															Article III of the Constitution limits the
jurisdiction of federal courts to “Cases” and “Controversies.” The
“case or controversy” requirement is “ ‘fundamental to the
judiciary’s proper role in our system of government.’ ”
Raines v. Byrd, 521 U.S.
811, 818 (1997) (quoting Simon v. Eastern Ky. Welfare
Rights Organization, 426 U.S.
26, 37 (1976)). Federal courts can only review statutes and
executive actions when necessary “to redress or prevent actual or
imminently threatened injury to persons caused by . . .
official violation of law.” Summers v. Earth Island
Institute, 555 U.S.
488, 492 (2009). As this Court has explained, “[i]f a dispute
is not a proper case or controversy, the courts have no business
deciding it, or expounding the law in the course of doing so.”
DaimlerChrysler Corp. v. Cuno, 547 U.S.
332, 341 (2006).

															A proper case or controversy exists only when at
least one plaintiff “establish[es] that [she] ha[s] standing to
sue.” Raines, 521 U. S., at 818; Department of
Commerce v. New York, 588 U.S. 752, 766 (2019). She must
show that she has suffered, or will suffer, an injury that is
“concrete, particularized, and actual or imminent; fairly traceable
to the challenged action; and redressable by a favorable ruling.”
Clapper v. Amnesty Int’l USA, 568
U.S. 398, 409 (2013) (internal quotation marks omitted). These
requirements help ensure that the plaintiff has “such a personal
stake in the outcome of the controversy as to warrant [her]
invocation of federal-court jurisdiction.” Summers, 555
U. S., at 493 (internal quotation marks omitted).

															The plaintiffs claim standing based on the
“direct censorship” of their own speech as well as their “right to
listen” to others who faced social-media censorship. Brief for
Respondents 19, 22. Notably, both theories depend on the
platform’s actions—yet the plaintiffs do not seek to enjoin
the platforms from restricting any posts or accounts. They seek to
enjoin Government agencies and officials from pressuring or
encouraging the platforms to suppress protected speech in the
future.

															The one-step-removed, anticipatory nature of
their alleged injuries presents the plaintiffs with two particular
challenges. First, it is a bedrock principle that a federal
court cannot redress “injury that results from the independent
action of some third party not before the court.” Simon, 426
U. S., at 41–42. In keeping with this principle, we have “been
reluctant to endorse standing theories that require guesswork as to
how independent decisionmakers will exercise their judgment.”
Clapper, 568 U. S., at 413. Rather than guesswork, the
plaintiffs must show that the third-party platforms “will likely
react in predictable ways” to the defendants’ conduct.
Department of Commerce, 588 U. S., at 768.
Second, because the plaintiffs request forward-looking
relief, they must face “a real and immediate threat of repeated
injury.” O’Shea v. Littleton, 414
U.S. 488, 496 (1974); see also Susan B. Anthony List v.
Driehaus, 573 U.S.
149, 158 (2014) (“An allegation of future injury may suffice if
the threatened injury is certainly impending, or there is a
substantial risk that the harm will occur” (internal quotation
marks omitted)). Putting these requirements together, the
plaintiffs must show a substantial risk that, in the near future,
at least one platform will restrict the speech of at least one
plaintiff in response to the actions of at least one Government
defendant. On this record, that is a tall order.

															Before we evaluate the plaintiffs’ different
theories, a few preliminaries: The plaintiff “bears the burden of
establishing standing as of the time [s]he brought th[e] lawsuit
and maintaining it thereafter.” Carney v. Adams, 592
U.S. 53, 59 (2020). She must support each element of standing “with
the manner and degree of evidence required at the successive stages
of the litigation.” Lujan v. Defenders of Wildlife,
504 U.S.
555, 561 (1992). At the preliminary injunction stage, then, the
plaintiff must make a “clear showing” that she is “likely” to
establish each element of standing. See Winter v. Natural
Resources Defense Council, Inc., 555 U.S.
7, 22 (2008) (emphasis deleted). Where, as here, the parties
have taken discovery, the plaintiff cannot rest on “mere
allegations,” but must instead point to factual evidence. See
Lujan, 504 U. S., at 561 (internal quotation marks
omitted).

															B

															1

															The plaintiffs’ primary theory of standing
involves their “direct censorship injuries.” They claim that the
restrictions they have experienced in the past on various platforms
are traceable to the defendants and that the platforms will
continue to censor their speech at the behest of the defendants. So
we first consider whether the plaintiffs have demonstrated
traceability for their past injuries.

															Here, a note of caution: If the plaintiffs were
seeking compensatory relief, the traceability of their past
injuries would be the whole ball game. But because the plaintiffs
are seeking only forward-looking relief, the past injuries are
relevant only for their predictive value. See O’Shea, 414
U. S., at 495–496 (“Past exposure to illegal conduct” can
serve as evidence of threatened future injury but “does not in
itself show a present case or controversy regarding injunctive
relief ”). If a plaintiff demonstrates that a particular
Government defendant was behind her past social-media restriction,
it will be easier for her to prove that she faces a continued risk
of future restriction that is likely to be traceable to that same
defendant. Conversely, if a plaintiff cannot trace her past injury
to one of the defendants, it will be much harder for her to make
that showing. See Clapper, 568 U. S., at 411. In the
latter situation, the plaintiff would essentially have to build her
case from scratch, showing why she has some newfound reason to fear
that one of the named defendants will coerce her chosen platform to
restrict future speech on a topic about which she plans to post—in
this case, either COVID–19 or the upcoming election. Keep in mind,
therefore, that the past is relevant only insofar as it is a
launching pad for a showing of imminent future injury.

															The primary weakness in the record of past
restrictions is the lack of specific causation findings with
respect to any discrete instance of content moderation. The
District Court made none. Nor did the Fifth Circuit, which
approached standing at a high level of generality. The platforms,
it reasoned, “have engaged in censorship of certain viewpoints on
key issues,” while “the government has engaged in a years-long
pressure campaign” to ensure that the platforms suppress those
viewpoints. 83 F. 4th, at 370. The platforms’ “censorship
decisions”—including those affecting the plaintiffs—were thus
“likely attributable at least in part to the platforms’ reluctance
to risk” the consequences of refusing to “adhere to the
government’s directives.” Ibid.

															We reject this overly broad assertion. As
already discussed, the platforms moderated similar content long
before any of the Government defendants engaged in the challenged
conduct. In fact, the platforms, acting independently, had
strengthened their pre-existing content-moderation policies before
the Government defendants got involved. For instance, Facebook
announced an expansion of its COVID–19 misinformation policies in
early February 2021, before White House officials began
communicating with the platform. And the platforms continued to
exercise their independent judgment even after communications with
the defendants began. For example, on several occasions, various
platforms explained that White House officials had flagged content
that did not violate company policy. Moreover, the platforms did
not speak only with the defendants about content moderation; they
also regularly consulted with outside experts.

															This evidence indicates that the platforms had
independent incentives to moderate content and often exercised
their own judgment. To be sure, the record reflects that the
Government defendants played a role in at least some of the
platforms’ moderation choices. But the Fifth Circuit, by
attributing every platform decision at least in part to the
defendants, glossed over complexities in the evidence.[4]

															The Fifth Circuit also erred by treating the
defendants, plaintiffs, and platforms each as a unified whole. Our
decisions make clear that “standing is not dispensed in gross.”
TransUnion LLC v. Ramirez, 594 U.S. 413, 431 (2021).
That is, “plaintiffs must demonstrate standing for each claim that
they press” against each defendant, “and for each form of relief
that they seek.” Ibid. Here, for every defendant, there must
be at least one plaintiff with standing to seek an injunction. This
requires a certain threshold showing: namely, that a particular
defendant pressured a particular platform to censor a particular
topic before that platform suppressed a particular
plaintiff ’s speech on that topic.

															Heeding these conditions is critically important
in a sprawling suit like this one. The plaintiffs faced speech
restrictions on different platforms, about different topics, at
different times. Different groups of defendants communicated with
different platforms, about different topics, at different times.
And even where the plaintiff, platform, time, content, and
defendant line up, the links must be evaluated in light of the
platform’s independent incentives to moderate content. As
discussed, the platforms began to suppress the plaintiffs’ COVID–19
content before the defendants’ challenged communications started,
which complicates the plaintiffs’ effort to demonstrate that each
platform acted due to “government-coerced enforcement” of its
policies, 83 F. 4th, at 370 (emphasis deleted), rather than in
its own judgment as an “ ‘independent acto[r],’ ”
Lujan, 504 U. S., at 562. With these factors in mind,
we proceed to untangle the mass of the plaintiffs’ injuries and
Government communications.

															2

															The plaintiffs rely on allegations of past
Government censorship as evidence that future censorship is likely.
But they fail, by and large, to link their past social-media
restrictions to the defendants’ communications with the platforms.
Thus, the events of the past do little to help any of the
plaintiffs establish standing to seek an injunction to prevent
future harms.

															Louisiana and Missouri. The state
plaintiffs devote minimal attention to restriction of their own
social-media content, much less to a causal link between any such
restriction and the actions of any Government defendant. They refer
only to Facebook’s “flagg[ing] . . . and de-boost[ing]”
of a Louisiana state representative’s post about children and the
COVID–19 vaccine. Brief for Respondents 20; App. 635–636. We need
not decide whether an injury to a state representative counts as an
injury to the State, because evidence of causation is
lacking.[5] The States assert
only that in November 2021, Facebook, “as a result of [its] work
[with the CDC],” updated its policies “to remove additional false
claims about the COVID–19 vaccine for children.” 37 Record 11,457.
But they never say when Facebook took action against the official’s
post—and a causal link is possible only if the removal occurred
after Facebook’s communication with the CDC. There is
therefore no evidence to support the States’ allegation that
Facebook restricted the state representative pursuant to the
CDC-influenced policy.

															Jayanta Bhattacharya, Martin Kulldorff, and
Aaron Kheriarty. These plaintiffs are doctors who questioned
the wisdom of then-prevailing COVID–19 policies, including
lockdowns and mask and vaccine mandates. Each faced his first
social-media restriction in 2020, before the White House and the
CDC entered discussions with the relevant platforms. Plaintiffs
highlight restrictions imposed by Twitter and LinkedIn, starting in
2021, on Dr. Kulldorff ’s posts about natural immunity. They
also point out that Twitter restricted the visibility of Dr.
Kheriarty’s posts about vaccine safety and efficacy, as well as the
ethics surrounding vaccine mandates. Attempting to show causation,
the plaintiffs emphasize that in January 2022, Facebook reported to
White House officials that it had recently demoted one post
advocating for natural immunity over vaccine immunity. But neither
the timing nor the platforms line up (nor, in Dr. Kheriarty’s case,
does the content), so the plaintiffs cannot show that these
restrictions were traceable to the White House officials. In fact,
there is no record evidence that White House officials ever
communicated at all with LinkedIn.

															Drs. Bhattacharya and Kulldorff claim that,
after disagreeing with the CDC and other federal health officials,
they faced a “relentless covert campaign of social-media
censorship.” App. 585 (emphasis deleted). They refer to the
platforms’ suppression of the Great Barrington Declaration, their
coauthored report calling for an end to lockdowns. But their
declarations do not suggest that anyone at the CDC was involved;
rather, they point to officials at the National Institutes of
Health and the NIAID. Those entities are not before us. With
nothing else to show, Drs. Bhattacharya, Kulldorff, and Kheriarty
have not established a likelihood that their past restrictions are
traceable to either the White House officials or the CDC.

															Jim Hoft. Both Hoft and his news website,
“The Gateway Pundit,” experienced election and COVID–19-related
restrictions on various platforms. Hoft tries to demonstrate his
standing to sue only the FBI and CISA, which means that only the
suppression of his election-related posts is relevant. (As already
discussed, the record contains no evidence that either the FBI or
CISA engaged with the platforms about the pandemic.) First, Hoft
points to the FBI’s role in the platforms’ adoption of
hacked-material policies. And he claims that Twitter, in December
2020, censored content about the Hunter Biden laptop story under
such a policy. The post was titled: “Where’s Hunter? How is Hunter
Celebrating the New Year? New Photos of Hunter Biden Pushing Drugs
on Women Emerge.” Hoft’s own declaration reveals that Twitter acted
according to its “rules against posting or sharing privately
produced/distributed intimate media of someone without their
express consent.” Id., at 608. Hoft provides no evidence
that Twitter adopted a policy against posting private, intimate
content in response to the FBI’s warnings about hack-and-leak
operations. Plus, it was Hoft’s brother, Joe Hoft, who posted this
tweet; Twitter therefore suspended Joe Hoft’s account. It is
unclear why Jim Hoft would have standing to sue for his brother’s
injury.

															Hoft claims that his content appears on a CISA
document tracking posts that various entities had flagged for the
platforms as misinformation. The spreadsheet shows that a private
entity, the Election Integrity Partnership—not CISA—alerted
Twitter to an unidentified article from the Gateway Pundit. And the
spreadsheet does not reveal whether Twitter removed or otherwise
suppressed that post. This evidence does not support the conclusion
that Hoft’s past injuries are likely traceable to the FBI or
CISA.

															Jill Hines. Of all the plaintiffs, Hines
makes the best showing of a connection between her social-media
restrictions and communications between the relevant platform
(Facebook) and specific defendants (CDC and the White House). That
said, most of the lines she draws are tenuous, particularly given
her burden of proof at the preliminary injunction stage—recall that
she must show that her restrictions are likely traceable to
the White House and the CDC.

															A healthcare activist, Hines codirects “Health
Freedom Louisiana,” a group that advocated against COVID–19 mask
and vaccine mandates. In October 2020—before the start of
communications with the White House and the bulk of communications
with the CDC—Facebook began to reduce the reach of Hines’ and
Health Freedom’s pages. Hines tries to connect Facebook’s
subsequent actions against her to both the White House officials
and the CDC.

															First, Facebook “deplatformed”
(i.e., deleted) one of Health Freedom’s groups in
July 2021. The last post in the group asked members to contact
state legislators about health freedom legislation. Three months
earlier, a White House official sent Facebook several “suggestions”
that were “circulating around the building and informing thinking,”
including that the platform should “end group recommendations for
groups with a history of COVID–19 or vaccine misinformation.” 54
Record 16,870–16,871. A week later, Facebook replied that it had
“already removed all health groups from our recommendation
feature.” App. 716. It is hard to know what to make of this.
Facebook reported that it had already acted, which tends to
imply that Facebook made its decision independently of the White
House. Moreover, Facebook and the White House communicated about
removing groups from recommendation features, not deleting them
altogether—further weakening the inference that Facebook was
implementing White House policy rather than its own.[6]

															Next, in April 2023, Facebook gave Hines a
warning after she reposted content from Robert F. Kennedy, Jr. Two
years earlier, White House officials had pushed Facebook to remove
the accounts of the “disinformation dozen,” 12 people (including
Kennedy) supposedly responsible for a majority of COVID–19-related
misinformation. Hines tries to link the warning she received to
this earlier White House pressure. Again, though, the link is weak.
There is no evidence that the White House asked Facebook to censor
every user who reposts a member of the disinformation dozen,
nor did Facebook change its policies to do so. Facebook’s 2023
warning to Hines bears only a tangential relationship to the White
House’s 2021 directive to Facebook.

															Hines traces her remaining restrictions to the
CDC. Beginning in October 2020, Facebook fact checked Hines’ posts
about pregnant women taking the COVID–19 vaccine, along with posts
including data from the Vaccine Adverse Event Reporting System
(VAERS). And in March 2021, the CDC flagged several misinformation
trends for Facebook, including claims related to pregnancy and
VAERS data. Because Hines does not provide dates for the fact
checks, we cannot know whether the CDC could be responsible.

															In May 2022, Facebook restricted Hines’ account
for posting an article discussing increased rates of myocarditis in
teenagers following vaccination. A little over a year earlier, the
CDC warned Facebook against claims of “unsubstantiated links to new
[vaccine] side effects,” including “ ‘irritab[ility],’ ”
“ ‘auto-immune issues, infertility,’ ” and
“ ‘neurological damage including lowered IQ.’ ” 54 Record
17,042–17,043 (emphasis deleted). There is no evidence that the CDC
ever listed myocarditis as an unsubstantiated side effect—but
because it is an alleged side effect, it at least falls under the
same umbrella as the CDC’s communication. Health Freedom’s February
2023 violation, by contrast, was for posting that vaccine
manufacturers would not compensate those with vaccine-related
injuries—a topic that bears little resemblance to the content that
the CDC flagged.

															In April 2023, Hines received violations for
posts about children and the vaccine. In November 2021, Facebook
worked with the CDC to update its policies to remove additional
false claims including that “ ‘the COVID vaccine is not safe
for kids.’ ” 37 id., at 11,457. It is not clear that
either of Hines’ posts violated the CDC-influenced policy against
false claims related to children and the vaccine. One simply
referred to the World Health Organization’s COVID–19 vaccine
recommendations for children, and the other discussed the role of
children within the “predatory” pharmaceutical industry. App.
789–790. Given the loose match between the policy and the posts, it
is hard to call it “likely” that Facebook was enforcing the CDC’s
preferences rather than its own.[7]

															With one or two potentially viable links, Hines
makes the best showing of all the plaintiffs. Still, Facebook was
targeting her pages before almost all of its communications with
the White House and the CDC, which weakens the inference that her
subsequent restrictions are likely traceable to “government-coerced
enforcement” of Facebook’s policies, 83 F. 4th, at 370
(emphasis deleted), rather than to Facebook’s independent
judgment.[8] Even assuming,
however, that Hines has eked out a showing of traceability for her
past injuries, the past is relevant only insofar as it predicts the
future. And this weak record gives her little momentum going
forward.

															3

															To obtain forward-looking relief, the
plaintiffs must establish a substantial risk of future injury that
is traceable to the Government defendants and likely to be
redressed by an injunction against them. To carry that burden, the
plaintiffs must proffer evidence that the defendants’ “allegedly
wrongful behavior w[ould] likely occur or continue.”
Friends of the Earth, Inc. v. Laidlaw Environmental
Services (TOC), Inc., 528 U.S.
167, 190 (2000). At the preliminary injunction stage, the
plaintiffs must show that they are likely to succeed in carrying
that burden. See Winter, 555 U. S., at 22. But without
proof of an ongoing pressure campaign, it is entirely speculative
that the platforms’ future moderation decisions will be
attributable, even in part, to the defendants.

															The plaintiffs treat the defendants as a
monolith, claiming broadly that “ ‘the governmen[t]’ ”
continues to communicate with the platforms about
“ ‘content-moderation issues.’ ” Brief for Respondents 29
(quoting 83 F. 4th, at 369). But we must confirm that
each Government defendant continues to engage in the
challenged conduct, which is “coercion” and “significant
encouragement,” not mere “communication.” Plus, the plaintiffs have
only explicitly identified an interest in speaking about COVID–19
or elections—so the defendants’ discussions about
content-moderation issues must focus on those topics.

															We begin with the plaintiffs who have not
pointed to any past restrictions likely traceable to the Government
defendants. This failure to establish traceability for past
harms—which can serve as evidence of expected future
harm—“substantially undermines [the plaintiffs’] standing theory.”
Clapper, 568 U. S., at 411. These plaintiffs
(i.e., everyone other than Hines) are thus particularly ill
suited to the task of establishing their standing to seek
forward-looking relief.

															Take Hoft, the only plaintiff who has expressed
interest in speaking about elections (and thus the only plaintiff
with potential standing to sue the FBI and CISA). The FBI’s
challenged conduct was ongoing at the time of the complaint, as the
agency worked with the platforms during the 2022 midterm election
season. Still, Hoft must rely on a “speculative chain of
possibilities” to establish a likelihood of future harm traceable
to the FBI. Id., at 414. Hoft’s future posts (presumably
about the 2024 Presidential election) must contain content that
falls within a misinformation trend that the FBI has identified or
will identify in the future. The FBI must pressure the platforms to
remove content within that category. The platform must then
suppress Hoft’s post, and it must do so at least partly in
response to the FBI, rather than in keeping with its own
content-moderation policy. Hoft cannot satisfy his burden with such
conjecture. CISA, meanwhile, stopped switchboarding in mid-2022,
and the Government has represented that it will not resume
operations for the 2024 election. Especially in light of his poor
showing of traceability in the past, Hoft has failed to demonstrate
likely future injury at the hands of the FBI or CISA—so the
injunction against those entities cannot survive.

															The doctors and the state plaintiffs, who focus
on COVID–19 content, have a similarly uphill battle vis-à-vis the
White House, the Surgeon General’s Office, and the CDC. Hines, with
her superior showing on past harm, is in a slightly better position
to demonstrate likely future harm at the hands of these defendants.
Still, she has not shown enough.

															Starting with the White House and Surgeon
General’s Office, the vast majority of their public and private
engagement with the platforms occurred in 2021, when the pandemic
was still in full swing. By August 2022, when Hines joined the
case, the officials’ communications about COVID–19 misinformation
had slowed to a trickle. Publicly, the White House Press Secretary
made two statements in February and April 2022. First, she said
that the platforms should continue “call[ing] out misinformation
and disinformation.” 3 Record 758. Two months later, she spoke
generally about §230 and antitrust reform, but did not mention
content moderation or COVID–19 misinformation. In March 2022, the
Surgeon General issued a voluntary “Request for Information” from
the platforms about their misinformation policies.[9]

															Privately, Facebook sent monthly “Covid
Insights” reports to officials in the White House and the Surgeon
General’s Office, at least until July 2022. These reports contained
information about the top 100 vaccine-related posts in the United
States, including whether Facebook took action against any of them.
In June, Facebook asked if it should continue sending these
reports, as it had stopped seeing “problematic vaccine related”
content in the top posts. 50 id., at 15,645–15,646. The
official replied that, though he would “normally say we are good to
discontinue,” the reports would be helpful “as we start to ramp up
. . . vaccines” for children under five. Id., at
15,645. The record contains no other evidence of private contact
with respect to COVID–19 misinformation.

															On this record, it appears that the frequent,
intense communications that took place in 2021 had considerably
subsided by 2022. (Perhaps unsurprisingly, given the changed state
of the pandemic.) It is thus very difficult for Hines to show that
she faces future harm that is traceable to officials in the White
House and the Surgeon General’s Office. Recall the Fifth Circuit’s
reasoning regarding traceability for past harms: In the face of a
governmental “pressure campaign,” the “platforms’ censorship
decisions were likely attributable at least in part to [their]
reluctance to risk the adverse legal or regulatory consequences
that could result from a refusal to adhere to the government’s
directives.” 83 F. 4th, at 370. But in the months leading up
to this suit, these officials issued no directives and threatened
no consequences. They only asked for information about the most
popular vaccine-related posts. Hines does not allege that her
content has fallen, or is likely to fall, in that category.

															In these circumstances, Hines cannot rely on
“the predictable effect of Government action on the decisions of
third parties”; rather, she can only “speculat[e] about the
decisions of third parties.” Department of Commerce, 588
U. S., at 768. It is “no more than conjecture” to assume that
Hines will be subject to White House-induced content moderation.
Los Angeles v. Lyons, 461 U.S.
95, 108 (1983). Hines (along with the other plaintiffs) has
therefore failed to establish a likelihood of future injury
traceable to the White House or the Surgeon General’s Office.
Likewise, the risk of future harm traceable to the CDC is minimal.
The CDC stopped meeting with the platforms in March 2022.
Thereafter, the platforms sporadically asked the CDC to verify or
debunk several claims about vaccines. But the agency has not
received any such message since the summer of 2022.[10]

															The plaintiffs’ counterarguments do not
persuade. First, they argue that they suffer “continuing,
present adverse effects” from their past restrictions, as they must
now self-censor on social media. O’Shea, 414 U. S., at
496. But the plaintiffs “cannot manufacture standing merely by
inflicting harm on themselves based on their fears of hypothetical
future harm that is not certainly impending.” Clapper, 568
U. S., at 416. And as we explained, the plaintiffs have not
shown that they are likely to face a risk of future censorship
traceable to the defendants. Indeed, even before the
defendants entered the scene, the plaintiffs “had a similar
incentive to engage in” self-censorship, given the platforms’
independent content moderation. Id., at 417. So it is
“difficult to see how” the plaintiffs’ self-censorship “can be
traced to” the defendants. Ibid.

															Second, the plaintiffs and the dissent
suggest that the platforms continue to suppress their speech
according to policies initially adopted under Government pressure.
Post, at 21. That may be true. But the plaintiffs have a
redressability problem. “To determine whether an injury is
redressable,” we “consider the relationship between ‘the judicial
relief requested’ and the ‘injury’ suffered.” California v.
Texas, 593 U.S. 659, 671 (2021). The plaintiffs assert
several injuries—their past social-media restrictions, current
self-censorship, and likely social-media restrictions in the
future. The requested judicial relief, meanwhile, is an injunction
stopping certain Government agencies and employees from coercing or
encouraging the platforms to suppress speech. A court could
prevent these Government defendants from interfering with the
platforms’ independent application of their policies. But without
evidence of continued pressure from the defendants, it appears that
the platforms remain free to enforce, or not to enforce, those
policies—even those tainted by initial governmental coercion. The
platforms are “not parties to the suit, and there is no reason they
should be obliged to honor an incidental legal determination the
suit produced.” Lujan, 504 U. S., at 569 (plurality
opinion); see also Haaland v. Brackeen, 599 U.S. 255,
293–294 (2023).

															Indeed, the available evidence indicates that
the platforms have enforced their policies against COVID–19
misinformation even as the Federal Government has wound down its
own pandemic response measures. For instance, Hines reports that
Facebook imposed several restrictions on her vaccine-related posts
in the spring of 2023. Around the same time, in April 2023,
President Biden signed a joint resolution that ended the national
COVID–19 emergency. See Pub. L. 118–3, 137Stat. 6. The next month,
the White House disbanded its COVID–19 Response Team, which was
responsible for many of the challenged communications in this case.
Enjoining the Government defendants, therefore, is unlikely to
affect the platforms’ content-moderation decisions.[11]

															C

															We conclude briefly with the plaintiffs’
“right to listen” theory. The individual plaintiffs claim an
interest in reading and engaging with the content of other speakers
on social media. The First Amendment, they argue, protects that
interest. Thus, the plaintiffs assert injuries based on the
restrictions that countless other social-media users have
experienced.

															This theory is startlingly broad, as it would
grant all social-media users the right to sue over someone
else’s censorship—at least so long as they claim an interest in
that person’s speech. This Court has “never accepted such a
boundless theory of standing.” Already, LLC v. Nike,
Inc., 568 U.S.
85, 99 (2013). While we have recognized a “ First Amendment
right to ‘receive information and ideas,’ ” we have identified
a cognizable injury only where the listener has a concrete,
specific connection to the speaker. Kleindienst v.
Mandel, 408 U.S.
753, 762 (1972). For instance, in Mandel, we agreed that
a group of professors had a First Amendment interest in challenging
the visa denial of a person they had invited to speak at a
conference. Id., at 762–765. And in Virginia Bd. of
Pharmacy v. Virginia Citizens Consumer Council, Inc., we
concluded that prescription-drug consumers had an interest in
challenging the prohibition on advertising the price of those
drugs. 425 U.S.
748, 756–757 (1976).

															Attempting to satisfy this requirement, the
plaintiffs emphasize that hearing unfettered speech on social media
is critical to their work as scientists, pundits, and activists.
But they do not point to any specific instance of content
moderation that caused them identifiable harm. They have therefore
failed to establish an injury that is sufficiently “concrete and
particularized.” Lujan, 504 U. S., at 560.

															The state plaintiffs, claiming their own version
of the “right to listen” theory, assert a sovereign interest in
hearing from their citizens on social media. See 83 F. 4th, at
372–373. But this theory suffers from the same flaws as the
individual plaintiffs’ theory. The States have not identified any
specific speakers or topics that they have been unable to hear or
follow.

															The States cite this supposed sovereign injury
as a basis for asserting third-party standing on behalf of “the
citizens they would listen to.” Brief for Respondents 30. But
“[t]his argument is a thinly veiled attempt to circumvent the
limits on parens patriae standing.” Brackeen, 599
U. S., at 295, n. 11. Namely, States do not have
“ ‘standing as parens patriae to bring an action
against the Federal Government.’ ” Id., at 295.

															The States, like the individual plaintiffs, have
failed to establish a likelihood of standing.

															*  *  *

															The plaintiffs, without any concrete link
between their injuries and the defendants’ conduct, ask us to
conduct a review of the years-long communications between dozens of
federal officials, across different agencies, with different
social-media platforms, about different topics. This Court’s
standing doctrine prevents us from “exercis[ing such] general legal
oversight” of the other branches of Government. TransUnion,
594 U. S., at 423–424. We therefore reverse the judgment of
the Fifth Circuit and remand the case for further proceedings
consistent with this opinion.

															

															It is so ordered.

Notes
1
 Since the events of this
suit, Twitter has merged into X Corp. and is now known as X.
Facebook is now known as Meta Platforms. For the sake of clarity,
we will refer to these platforms as Twitter and Facebook, as they
were known during the vast majority of the events underlying this
suit.
2
 The District Court also
enjoined the National Institute of Allergy and Infectious Diseases
(NIAID) and the State Department, along with their officials and
employees. 680 F. Supp. 3d, at 700–701, 704–705. The Fifth
Circuit removed these entities and individuals from the injunction,
however, so they are not before us. Missouri v.
Biden, 83 F. 4th 350, 391 (2023).
3
 Because we do not reach
the merits, we express no view as to whether the Fifth Circuit
correctly articulated the standard for when the Government
transforms private conduct into state action.
4
 The Fifth Circuit relied
on the District Court’s factual findings, many of which
unfortunately appear to be clearly erroneous. The District Court
found that the defendants and the platforms had an “efficient
report-and-censor relationship.” Missouri v. Biden,
680 F. Supp. 3d 630, 715 (WD La. 2023). But much of its
evidence is inapposite. For instance, the court says that Twitter
set up a “streamlined process for censorship requests” after the
White House “bombarded” it with such requests. Ibid., n. 662
(internal quotation marks omitted). The record it cites says
nothing about “censorship requests.” See App. 639–642. Rather, in
response to a White House official asking Twitter to remove an
impersonation account of President Biden’s granddaughter, Twitter
told the official about a portal that he could use to flag similar
issues. Ibid. This has nothing to do with COVID–19
misinformation. The court also found that “[a] drastic increase in
censorship . . . directly coincided with Defendants’
public calls for censorship and private demands for censorship.”
680 F. Supp. 3d, at 715. As to the “calls for censorship,” the
court’s proof included statements from Members of Congress, who are
not parties to this suit. Ibid., and n. 658. Some of the
evidence of the “increase in censorship” reveals that Facebook
worked with the CDC to update its list of removable false claims,
but these examples do not suggest that the agency “demand[ed]” that
it do so. Ibid. Finally, the court, echoing the plaintiffs’
proposed statement of facts, erroneously stated that Facebook
agreed to censor content that did not violate its policies.
Id., at 714, n. 655. Instead, on several occasions,
Facebook explained that certain content did not qualify for
removal under its policies but did qualify for other forms
of moderation.
5
 The Fifth Circuit held
that States “sustain a direct injury when the social-media accounts
of state officials are censored due to federal coercion.” 83 F.
4th, at 372. Because the State failed to show that its official was
censored, we need not express a view on this theory.
6
 Hines tries to link this
restriction to the Surgeon General’s Office as well, suggesting
that the White House and Surgeon General together pressured
Facebook. But the record reveals that a White House official sent
the relevant email, and Facebook responded only to White House
officials. The Surgeon General’s Office was seemingly uninvolved.
Thus, Hines cannot demonstrate that her past restriction is
traceable to the Surgeon General’s Office. The plaintiffs do not
attempt to draw any other connections between their restrictions
and the Surgeon General’s Office.
7
 The dissent does not
dispute the Court’s assessment of these asserted links. Instead,
the dissent draws links that Hines herself has not set forth, often
based on injuries that Hines never claimed. Compare post, at
19–20, with Brief for Respondents 19–20; App. 628–632. For
instance, the dissent says that in May 2021, Facebook began
demoting content from accounts that repeatedly shared
misinformation, purportedly due to White House pressure.
Post, at 10, 19. Because Facebook frequently fact checked
Hines’ posts, the dissent simply assumes (without citing Hines’
declarations) that her content was subsequently hidden from her
friends’ feeds. Post, at 19. Likewise, pointing to an August
2021 policy change, the dissent concludes that the mid-July 2021
deplatforming of one of Hines’ groups rendered her other pages
“non-recommendable.” Ibid. Hines, however, never claimed as
much—and the plaintiffs bear the burden to establish
standing by setting forth “specific facts.” Lujan v.
Defenders of Wildlife, 504 U.S.
555, 561 (1992) (internal quotation marks omitted). It is
especially important to hold the plaintiffs to their burden in a
case like this one, where the record spans over 26,000 pages and
the lower courts did not make any specific causation findings. As
the Seventh Circuit has memorably put it, “[j]udges are not like
pigs, hunting for truffles buried [in the record].” Gross v.
Cicero, 619 F.3d 697, 702 (2010) (internal quotation marks
omitted).
8
 By acknowledging the real
possibility that Facebook acted independently in suppressing Hines’
content, we are not applying a “new and heightened standard,” as
the dissent claims. Post, at 20. The whole purpose of the
traceability requirement is to ensure that “in fact, the asserted
injury was the consequence of the defendants’ actions,” rather than
of “the independent action” of a third party. Simon v.
Eastern Ky. Welfare Rights Organization, 426 U.S.
26, 42, 45 (1976). Nor is our analysis inconsistent with
Department of Commerce v. New York, 588 U.S. 752
(2019). See post, at 19. There, the plaintiffs, including
several States, challenged the Secretary of Commerce’s decision to
reinstate a citizenship question on the census. 588 U. S., at
761, 764. They argued that this question would make noncitizens
less likely to respond to the census, leading to an inaccurate
population count and the concomitant loss of congressional seats
and federal funding. Id., at 766–767. The plaintiffs’
injuries thus depended on the actions of third parties. Id.,
at 767–768. The District Court found that noncitizens had
historically responded at lower rates than citizens to previous
versions of the census (and other surveys) that included a
citizenship question and that noncitizens were disproportionately
likely to stop responding to those questionnaires once they reached
the citizenship question. New York v. United States Dept.
of Commerce, 351 F. Supp. 3d 502, 578–579 (SDNY 2019).
Crediting those findings, this Court concluded that the plaintiffs
“met their burden of showing that third parties will likely react
in predictable ways to the citizenship question.”
Department of Commerce, 588 U. S., at 768. The dissent
suggests that it “would have been difficult for [the plaintiffs] to
determine which noncitizen households failed to respond to the
census because of a citizenship question and which had other
reasons.” Post, at 20. But the evidence made clear that the
citizenship question drove noncitizens’ lower response
rates; the District Court made no findings about noncitizens’
response rates to the census generally. Here, by contrast, the
evidence is murky. Facebook targeted Hines’ posts (and others like
hers) before the White House entered the picture, meaning that
Facebook had independent incentives to restrict Hines’ content. It
is therefore difficult to say that the White House was responsible
(even in part) for all of Hines’ later
restrictions—especially absent clear links between White
House content-moderation requests to Facebook and Facebook’s
actions toward Hines. Cf. post, at 21.
9
 According to a
declaration submitted by the Surgeon General’s Chief of Staff, no
one in that office met with the platforms to discuss their
submissions “or otherwise had substantive communications with
social media companies about the RFI.” 61 Record
19,480.
10  The
dissent claims that the future injury prong is satisfied because
Facebook continued to censor Hines at the time of her complaint and
thereafter. Post, at 17. But the dissent gives short shrift
to the key point: By the time Hines filed suit in August 2022, the
White House was no longer engaged in any sort of “pressure
campaign” toward Facebook. (Note that the dissent, in its 10-page
recounting of the record, devotes only one paragraph to the events
of 2022. Post, at 14.) Thus, when Hines sued, it was
unlikely that Facebook’s actions were fairly traceable to the White
House at the time—or would be going forward.
11  As
with traceability, the dissent is wrong to claim that we are
applying a “new and elevated standard for redressability.”
Post, at 22. Far from holding plaintiffs to a “certainty”
standard, ibid., we simply conclude that an injunction
against the Government defendants is unlikely to stop the
platforms from suppressing the plaintiffs’ speech. And while
traceability and redressability are “ ‘often “flip
sides of the same coin,” ’ ” post, at 22 (quoting
FDA v. Alliance for Hippocratic Medicine, 602 U.S.
367, 380 (2024); emphasis added), that is not always the
case. Facebook might continue to remove Hines’ posts under a policy
that it adopted at the White House’s behest (thus satisfying
traceability). But if the White House officials have already
abandoned their pressure campaign, enjoining them is unlikely to
prompt Facebook to stop enforcing the policy (thus failing
redressability). Finally, by invoking Massachusetts v.
EPA, it is the dissent that applies a new and
loosened standard for redressability. Post, at 22. In that
case, we explained that state plaintiffs are “entitled to
special solicitude” when it comes to standing, and we conducted our
analysis accordingly. 549 U.S.
497, 520 (2007). That “special solicitude” does not apply to
Jill Hines, an individual.


