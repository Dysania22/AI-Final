{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load spaCy model for advanced preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the SciBERT tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"vAAvEdRZ.JMceyc7bQU6WnoXFF6M79GPKz3I5Jo4d\"\n",
    "# API base URL for the PatentSearch API\n",
    "PATENTSEARCH_API_URL = \"https://search.patentsview.org/api/v1/patent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for advanced text preprocessing with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_spacy(text):\n",
    "    doc = nlp(text.lower())  # Process text with spaCy\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        # Remove stopwords, punctuation, and keep only nouns/adjectives/verbs\n",
    "        if not token.is_stop and not token.is_punct and token.pos_ in ('NOUN', 'VERB', 'ADJ'):\n",
    "            tokens.append(token.lemma_)  # Lemmatize the token (e.g., \"running\" -> \"run\")\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to query the PatentSearch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_patentsearch(query_text, num_results=10):\n",
    "    headers = {\n",
    "        'X-Api-Key': API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    # Construct the query object\n",
    "    query = {\n",
    "        \"patent_abstract\": f\"_text_any: {query_text}\"\n",
    "    }\n\n",
    "    # Specify the fields you want (patent_abstract, patent_title, patent_date, etc.)\n",
    "    fields = [\"patent_id\", \"patent_title\", \"patent_abstract\", \"patent_date\"]\n\n",
    "    # Prepare API parameters\n",
    "    params = {\n",
    "        \"q\": json.dumps(query),  # Ensure query is JSON encoded\n",
    "        \"f\": json.dumps(fields),  # Specify the fields to return\n",
    "        \"per_page\": 10,  # Number of results to return\n",
    "        \"page\": 1  # Page number (for pagination)\n",
    "    }\n\n",
    "    # Send GET request to the API\n",
    "    response = requests.get(PATENTSEARCH_API_URL, params=params, headers=headers)\n\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('patents', [])\n",
    "    else:\n",
    "        print(f\"Error querying PatentSearch API: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate SciBERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n\n",
    "    # Get the embeddings from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n\n",
    "    # Use the mean of the token embeddings as the sentence embedding\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(query_embedding, patent_embeddings):\n",
    "    similarities = cosine_similarity(query_embedding, patent_embeddings)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to rank patents based on similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_patents(query_text, patents):\n",
    "    # Preprocess the patent abstracts using spaCy\n",
    "    patent_texts = [preprocess_text_spacy(patent['patent_abstract']) for patent in patents]\n\n",
    "    # Generate embeddings for the query and patents\n",
    "    query_embedding = get_embedding(preprocess_text_spacy(query_text))\n",
    "    patent_embeddings = np.vstack([get_embedding(text) for text in patent_texts])\n\n",
    "    # Calculate similarity scores\n",
    "    similarities = calculate_similarity(query_embedding, patent_embeddings)\n\n",
    "    # Rank patents by similarity\n",
    "    ranked_patents = sorted(\n",
    "        zip(patents, similarities[0]), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    return ranked_patents, patent_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to perform K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_patents(patent_embeddings, num_clusters=3):\n",
    "    # Perform K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(patent_embeddings)\n",
    "    return clusters, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_cluster(patents):\n",
    "    all_text = ' '.join([patent['patent_title'] + ' ' + patent['patent_abstract'] for patent in patents])\n",
    "    tokens = preprocess_text_spacy(all_text).split()  # Preprocess the text using spaCy\n",
    "    counter = Counter(tokens)  # Count word frequencies\n",
    "    # Get the 5 most common words\n",
    "    most_common_words = [word for word, freq in counter.most_common(5)]\n",
    "    return ', '.join(most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function to run the prior art search and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_art_search(input_patent_text, num_clusters=3):\n",
    "    # Step 1: Query the PatentSearch API to get relevant patents\n",
    "    print(\"Querying PatentSearch API for similar patents...\")\n",
    "    patents = query_patentsearch(input_patent_text, num_results=10)\n",
    "    if not patents:\n",
    "        print(\"No patents found.\")\n",
    "        return\n\n",
    "    # Step 2: Rank patents based on their similarity to the input text\n",
    "    #print(f\"{patents}\")\n",
    "    print(\"Ranking patents based on semantic similarity...\")\n",
    "    ranked_patents, patent_embeddings = rank_patents(input_patent_text, patents)\n\n",
    "    # Step 3: Select only the top 15 most similar patents\n",
    "    top_patents = ranked_patents[:15]  # Select the top 15 ranked patents\n",
    "    top_patent_embeddings = np.vstack([get_embedding(preprocess_text_spacy(patent['patent_abstract'])) for patent, _ in top_patents])\n\n",
    "    # Step 3: Display the top ranked patents\n",
    "    print(\"\\nTop 5 most similar patents:\")\n",
    "    for idx, (patent, similarity) in enumerate(ranked_patents[:5], 1):\n",
    "        print(f\"{idx}. Patent Number: {patent['patent_id']}\")\n",
    "        print(f\"   Title: {patent['patent_title']}\")\n",
    "        print(f\"   Abstract: {patent['patent_abstract']}\")\n",
    "        print(f\"   Similarity: {similarity:.4f}\")\n",
    "        print(f\"   Date: {patent['patent_date']}\")\n",
    "        print(\"\\n\")\n\n",
    "    # Step 4: Perform K-Means clustering on the patent embeddings\n",
    "    print(f\"Clustering patents into {num_clusters} clusters...\")\n",
    "    clusters, kmeans = cluster_patents(top_patent_embeddings, num_clusters)\n\n",
    "    # Step 5: Display the patents in each cluster\n",
    "    print(\"\\nPatents clustered into groups:\")\n",
    "    for cluster_id in range(num_clusters):\n",
    "        clustered_groups = [patent for i, (patent, _) in enumerate(top_patents) if clusters[i] == cluster_id]\n\n",
    "        # Step 6: Generate and print the cluster summary\n",
    "       # print(f\"\\nSummary of Cluster {cluster_id + 1}:\")\n",
    "        summary = summarize_cluster(clustered_groups)  # Generate a summary for the cluster\n",
    "        #print(f\"   Most common words: {summary}\")\n\n",
    "        # Print the cluster number\n",
    "        print(f\"\\nCluster {cluster_id + 1}: Summary - {summary}\")\n\n",
    "        # Print patents in this cluster\n",
    "        for patent in clustered_groups:\n",
    "            print(f\" - {patent['patent_id']}: {patent['patent_title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input patent text (abstract/claims)\n",
    "    input_patent_text = \"a motor positioned above the water chamber and coupled to the basket, the motor agitating the basket\"\n",
    "    # Replace with actual patent text or abstract)\n",
    "    num_clusters = 3\n",
    "    prior_art_search(input_patent_text, num_clusters=num_clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
